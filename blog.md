- Goal is to make artsy visuals from my sporting history, all tracked with polar and wahoo, over the past ten years. The idea that got me started is the "weeks in your life" poster from Kurzgesagt. I want to make something similar but then with sporting weeks in 10 years, showing volume per week, sports done in one big overview, like a 10 x50 grid with popping colrs. The end goal is to make it so pretty my wife allows me to print it and hang it somewhere in the house. 
- My sporting carreer should show some interesting patterns. Starting in 2015, I became a student athlete in rowing. Something like varsity squads in the USA. It's quite a scene in the Netherlands with cool but weird culture to go along (link to something). After rowing form 3 years I started cycling competitively. With the start of working and recently becoming a dad, we can really get a cool perspective of my sporting past and how it has changed over the years. Sporting is important to me. 
- Big inspiration is Nadie Bremer and https://www.data-to-art.com/
- The plan is to download all the data, store them on Hetzner object storage, use a VPS with remote development to do the analysis - extract metadata and useful information an write them to reusable formats before we even start visuallysing. 
- Started of by trying to get all data from intervals.icu, which I really like and have used for a really long time. All my data is there anyways. But due to the strava service agreement, downstream applications cannot share the data. Since the app is so great and we can get all sorts of data from there - the api docs are really extensive too -  we will just keep the client for later.
- Btw, I do this the centaur (backlink) way of developing. I scaffold the folder, choose the platforms and dependencies and the code practices but also let the agent (codex atm, claude code is cool too) in on the work. For instance, I just download the whole open API spec into the repo so that it can easier infer the right schemas and endpoints when I'd like it to.
- So, later I found that strava has this download archive feature and that some cool bloke on the internet (we've got plenty!) actually open sourced a really nice [side project](https://github.com/liskin/strava-offline) of his, that allows us to extract the metadata and some activity data into a database. It's two years old, but the code might give us a nice starting point or some pointers. There was a [MLE](https://www.reddit.com/r/dataengineering/comments/vjkarw/elt_of_my_own_strava_data_using_the_strava_api/) that built a [data pipeline](https://github.com/jackmleitch/StravaDataPipline) too, but that's 4 years ago and no longer applicable unfortunatly. 
- Strava does not make this easy, as you have to go into settings > acount > delete your account flow in orde to find the request archive as the second step in the exit flow. Knowing that the heavily throttled API they offer (insert limits), the only real option is to request the whole dataset through this feature and (if wanted) incrementally extend the dataset with thier API.
- So from strava_initial_analysis.py we get a couple of insights:
  - Strava data is only from may 2017 onwards, we need to get this data from polar it seems
  - Covers little to none of my rowing carreer
  - Before merging the data is a bit over the place
  - Ride is more dominant than I anticipated, both in volume and counts